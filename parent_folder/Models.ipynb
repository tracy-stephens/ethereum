{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4279a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "# Directory\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f8cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm sagemaker role exists\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='arn:aws:iam::971504885040:role/SageMaker')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c34e2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import files from S3\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "bucket = \"sagemaker-w210-eth\"\n",
    "\n",
    "# Txt file\n",
    "data_key = '2021-09-01/transaction_hashes_13136427_13142881.txt'\n",
    "s3_client = boto3.client('s3')\n",
    "obj = s3_client.get_object(Bucket=bucket, Key=data_key)\n",
    "contents = obj['Body'].read()\n",
    "print(contents.decode(\"utf-8\"))\n",
    "\n",
    "# CSV file\n",
    "# file_key = '2021-09-01/tokens_13136427_13142881.csv'\n",
    "# s3_client = boto3.client('s3')\n",
    "# obj = s3_client.get_object(Bucket=bucket, Key=file_key)\n",
    "# df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c82f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install awswrangler\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "df = wr.s3.read_parquet(path=\"s3://sagemaker-w210-eth/transactions_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37a68fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>block_number</th>\n",
       "      <th>transaction_index</th>\n",
       "      <th>value</th>\n",
       "      <th>gas</th>\n",
       "      <th>gas_price</th>\n",
       "      <th>block_timestamp</th>\n",
       "      <th>max_fee_per_gas</th>\n",
       "      <th>max_priority_fee_per_gas</th>\n",
       "      <th>transaction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298866400102</td>\n",
       "      <td>12988664</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>21000</td>\n",
       "      <td>28600000000</td>\n",
       "      <td>1628481908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298866500010</td>\n",
       "      <td>12988665</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>94813</td>\n",
       "      <td>57555038094</td>\n",
       "      <td>1628481912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298866500055</td>\n",
       "      <td>12988665</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>42000</td>\n",
       "      <td>35000000000</td>\n",
       "      <td>1628481912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298866500083</td>\n",
       "      <td>12988665</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>46769</td>\n",
       "      <td>32198530871</td>\n",
       "      <td>1628481912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298866500091</td>\n",
       "      <td>12988665</td>\n",
       "      <td>91</td>\n",
       "      <td>None</td>\n",
       "      <td>228523</td>\n",
       "      <td>31777519047</td>\n",
       "      <td>1628481912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100469</th>\n",
       "      <td>1304551200123</td>\n",
       "      <td>13045512</td>\n",
       "      <td>123</td>\n",
       "      <td>None</td>\n",
       "      <td>21000</td>\n",
       "      <td>76252437559</td>\n",
       "      <td>1629239526</td>\n",
       "      <td>1.310000e+11</td>\n",
       "      <td>5.000000e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100470</th>\n",
       "      <td>1304551200141</td>\n",
       "      <td>13045512</td>\n",
       "      <td>141</td>\n",
       "      <td>None</td>\n",
       "      <td>168354</td>\n",
       "      <td>75252437559</td>\n",
       "      <td>1629239526</td>\n",
       "      <td>9.185806e+10</td>\n",
       "      <td>4.000000e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100471</th>\n",
       "      <td>1304551200161</td>\n",
       "      <td>13045512</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>250000</td>\n",
       "      <td>73000000000</td>\n",
       "      <td>1629239526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100472</th>\n",
       "      <td>1304551300008</td>\n",
       "      <td>13045513</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>207128</td>\n",
       "      <td>114000000000</td>\n",
       "      <td>1629239547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100473</th>\n",
       "      <td>1304551300015</td>\n",
       "      <td>13045513</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>400000</td>\n",
       "      <td>101452126359</td>\n",
       "      <td>1629239547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32346859 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transaction_id  block_number  transaction_index value     gas  \\\n",
       "0         1298866400102      12988664                102  None   21000   \n",
       "1         1298866500010      12988665                 10     0   94813   \n",
       "2         1298866500055      12988665                 55  None   42000   \n",
       "3         1298866500083      12988665                 83     0   46769   \n",
       "4         1298866500091      12988665                 91  None  228523   \n",
       "...                 ...           ...                ...   ...     ...   \n",
       "1100469   1304551200123      13045512                123  None   21000   \n",
       "1100470   1304551200141      13045512                141  None  168354   \n",
       "1100471   1304551200161      13045512                161     0  250000   \n",
       "1100472   1304551300008      13045513                  8  None  207128   \n",
       "1100473   1304551300015      13045513                 15     0  400000   \n",
       "\n",
       "            gas_price  block_timestamp  max_fee_per_gas  \\\n",
       "0         28600000000       1628481908              NaN   \n",
       "1         57555038094       1628481912              NaN   \n",
       "2         35000000000       1628481912              NaN   \n",
       "3         32198530871       1628481912              NaN   \n",
       "4         31777519047       1628481912              NaN   \n",
       "...               ...              ...              ...   \n",
       "1100469   76252437559       1629239526     1.310000e+11   \n",
       "1100470   75252437559       1629239526     9.185806e+10   \n",
       "1100471   73000000000       1629239526              NaN   \n",
       "1100472  114000000000       1629239547              NaN   \n",
       "1100473  101452126359       1629239547              NaN   \n",
       "\n",
       "         max_priority_fee_per_gas  transaction_type  \n",
       "0                             NaN                 0  \n",
       "1                             NaN                 0  \n",
       "2                             NaN                 0  \n",
       "3                             NaN                 0  \n",
       "4                             NaN                 0  \n",
       "...                           ...               ...  \n",
       "1100469              5.000000e+09                 2  \n",
       "1100470              4.000000e+09                 2  \n",
       "1100471                       NaN                 0  \n",
       "1100472                       NaN                 0  \n",
       "1100473                       NaN                 0  \n",
       "\n",
       "[32346859 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01a770b4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce71400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor    \n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"OK\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07467c53",
   "metadata": {},
   "source": [
    "## Create train / dev / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_columns = []\n",
    "y_column = []\n",
    "\n",
    "X_train = data[data.timestamp<'10/01/2021'][X_columns]\n",
    "Y_train = data[data.timestamp<'10/01/2021'][Y_column]\n",
    "\n",
    "X_dev = data[(data.timestamp>='10/01/2021') & (data.timestamp<='11/01/2021')][X_columns]\n",
    "Y_dev = data[(data.timestamp>='10/01/2021') & (data.timestamp<='11/01/2021')][Y_column]\n",
    "\n",
    "X_test = data[data.timestamp>'11/01/2021'][X_columns]\n",
    "Y_test = data[data.timestamp>'11/01/2021'][Y_column]\n",
    "\n",
    "#create data sets that concatenates X's and y's for EDA\n",
    "train_data = X_train.copy()\n",
    "dev_data = X_dev.copy()\n",
    "test_data = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a7520",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call in the LinearRegression object\n",
    "lin_reg = LinearRegression(normalize=True, n_jobs=-1)\n",
    "\n",
    "lin_reg_features = []\n",
    "\n",
    "# fit train and test data. \n",
    "lin_reg.fit(X_train[lin_reg_features], Y_train)\n",
    "\n",
    "\n",
    "# Predict dev data. \n",
    "y_dev_pred = lin_reg.predict(X_dev)\n",
    "\n",
    "lr_mse = mean_squared_error(y_dev, y_dev_pred)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_dev, y_dev_pred))\n",
    "lr_r2score = metrics.r2_score(y_dev, y_dev_pred)\n",
    "\n",
    "print ('The MSE of the Linear Regression model is: %.4f'%lr_mse)\n",
    "print ('The RMSE of the Linear Regression model is: %.4f'%lr_rmse)\n",
    "print ('The R^2 of the Linear Regression model is: %.4f'%lr_r2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89885e",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=0.75, random_state=42)\n",
    "ridge_reg.fit(X_train[lin_reg_features], Y_train)\n",
    "rr_train_preds = ridge_reg.predict(X_train[lin_reg_features])\n",
    "rr_dev_preds = ridge_reg.predict(X_dev[lin_reg_features])\n",
    "\n",
    "rr_train_mse = mean_squared_error(Y_train, rr_train_preds)\n",
    "rr_train_rmse = np.sqrt(rr_train_mse)\n",
    "rr_train_r2score = metrics.r2_score(Y_train, rr_train_preds)\n",
    "rr_dev_mse = mean_squared_error(y_dev, rr_dev_preds)\n",
    "rr_dev_rmse = np.sqrt(rr_dev_mse)\n",
    "rr_dev_r2score = metrics.r2_score(Y_dev, rr_dev_preds)\n",
    "\n",
    "#print ('The MSE of the train Ridge Regression model is: %.4f'%rr_train_mse)\n",
    "print ('The RMSE of the train Ridge Regression model is: %.4f'%rr_train_rmse)\n",
    "print ('The R^2 of the train Ridge Regression model is: %.4f'%rr_train_r2score)\n",
    "#print ('The MSE of the dev Ridge Regression model is: %.4f'%rr_dev_mse)\n",
    "print ('The RMSE of the dev Ridge Regression model is: %.4f'%rr_dev_rmse)\n",
    "print ('The R^2 of the dev Ridge Regression model is: %.4f'%rr_dev_r2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea669a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the random forest\n",
    "rf = RandomForestRegressor(n_estimators = 1000, max_depth = 3, bootstrap = True, max_features = 4, \n",
    "                           min_samples_leaf = 50, random_state = 42)\n",
    "\n",
    "rf_features = X_train\n",
    "\n",
    "#Train the model on the training data\n",
    "rf.fit(X_train[rf_features], y_train)\n",
    "\n",
    "#Get the predictions on the training data set\n",
    "rf_train_predictions = rf.predict(X_train[rf_features])\n",
    "\n",
    "#Get the predictions on the dev data set\n",
    "rf_dev_predictions = rf.predict(X_dev[rf_features])\n",
    "\n",
    "\n",
    "rf_MSE_train = mean_squared_error(Y_train, rf_train_predictions)\n",
    "rf_MSE_dev = mean_squared_error(Y_dev, rf_dev_predictions)\n",
    "print(rf_MSE_train)\n",
    "print(rf_MSE_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c58a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importances = rf.feature_importances_\n",
    "rf_feature_importances_dict = {'Features': rf_features,\n",
    "                               'Feature_Importance': rf_feature_importances}\n",
    "rf_feature_importances_df = pd.DataFrame(rf_feature_importances_dict)\n",
    "rf_feature_importances_df.sort_values(by=['Feature_Importance'], \n",
    "                                      ascending=False,\n",
    "                                      inplace=True)\n",
    "print(rf_feature_importances_df.head(30))\n",
    "\n",
    "rf_feature_importances_df = rf_feature_importances_df.set_index('Features')\n",
    "rf_feature_importances_df['Feature_Importance'].nlargest(15).plot(kind='barh',\n",
    "                                                                  title='Random Forest Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574693f6",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features = []\n",
    "\n",
    "#set up the training matrix\n",
    "dtrain = xgb.DMatrix(X_train[xgb_features], label=Y_train)\n",
    "xgb_dict = {\n",
    "        'booster': 'dart',\n",
    "        #'booster': 'gbtree',\n",
    "        #'booster': 'gblinear',\n",
    "        'max_depth': 3,\n",
    "        'random_state': 42,\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'verbosity': 0,\n",
    "        'sample_type': 'uniform',\n",
    "        'subsample': 0.6,\n",
    "        'normalize_type': 'tree',\n",
    "        'rate_drop': 0.0,\n",
    "        #'rate_drop': 0.2,\n",
    "        'skip_drop': 0.2,\n",
    "        'min_child_weight': 5,\n",
    "        \n",
    "    }\n",
    "#starting hyperparameter of training rounds\n",
    "training_rounds = 1000\n",
    "\n",
    "#train the model\n",
    "bst = xgb.train(\n",
    "    xgb_dict,\n",
    "    dtrain,\n",
    "    training_rounds,\n",
    "    evals=[(xgb.DMatrix(X_dev[xgb_features], label=Y_dev), 'RMSE')],\n",
    "    early_stopping_rounds=10) \n",
    "\n",
    "\n",
    "training_rounds = bst.best_ntree_limit\n",
    " \n",
    "#get training predictions and MSE\n",
    "xgb_train_pred = bst.predict(xgb.DMatrix(X_train[xgb_features]), ntree_limit=training_rounds)\n",
    "xgb_train_mse = mean_squared_error(xgb_train_pred, Y_train)\n",
    "xgb_train_rmse = np.sqrt(xgb_train_mse)\n",
    "\n",
    "#print(\"XGB train mean squared error:\", xgb_train_mse)\n",
    "print(\"XGB train root mean squared error:\", xgb_train_rmse)\n",
    "\n",
    "#get dev predictions and MSE\n",
    "xgb_dev_pred = bst.predict(xgb.DMatrix(X_dev[xgb_features]), ntree_limit=training_rounds)\n",
    "xgb_dev_mse = mean_squared_error(xgb_dev_pred, Y_dev)\n",
    "xgb_dev_rmse = np.sqrt(xgb_dev_mse)\n",
    "\n",
    "#print(\"XGB dev mean squared error:\", xgb_dev_mse)\n",
    "print(\"XGB dev root mean squared error:\", xgb_dev_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9cd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "xgb_importance_weight = bst.get_score(importance_type='weight')\n",
    "xgb_importance_gain = bst.get_score(importance_type='gain')\n",
    "xgb_importance_weight_df = pd.DataFrame.from_dict(xgb_importance_weight,\n",
    "                                                  orient='index',\n",
    "                                                  columns=['weight'])\n",
    "xgb_importance_gain_df = pd.DataFrame.from_dict(xgb_importance_gain,\n",
    "                                                  orient='index',\n",
    "                                                  columns=['gain'])\n",
    "xgb_feature_importance_df = xgb_importance_weight_df.join(xgb_importance_gain_df)\n",
    "xgb_feature_importance_df.sort_values(by=['weight'], ascending=False, inplace=True)                 \n",
    "print(xgb_feature_importance_df.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(bst, max_num_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48da37",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_preds = (lr_preds_train + rr_train_preds + rf_train_predictions + xgb_train_pred) / 4\n",
    "print(\"train_rmse =\", np.sqrt(mean_squared_error(ensemble_train_preds, Y_train)))\n",
    "ensemble_dev_preds = (lr_preds_dev + rf_dev_predictions + xgb_dev_pred) / 3\n",
    "print(\"dev_rmse =\", np.sqrt(mean_squared_error(ensemble_dev_preds, Y_dev)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
